{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import path\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynteticSet(data.Dataset):\n",
    "    def __init__(self, df, features, target=\"target\"):\n",
    "        target_dict = {\"Class_1\": 0, \"Class_2\": 1, \"Class_3\": 2, \"Class_4\": 3}\n",
    "        \n",
    "        for i in target_dict:\n",
    "            df[target][df[target] == i] = target_dict[i]\n",
    "           \n",
    "        prefix = \"feature_{}\"\n",
    "        \n",
    "        for i,feature in enumerate(features):\n",
    "            features[i] = prefix.format(str(feature))\n",
    "        \n",
    "            \n",
    "        self.X = torch.tensor(df[features].to_numpy()).float()\n",
    "        self.Y = torch.tensor(df[target].to_numpy(dtype=np.int64))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i].abs().long(), self.Y[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-4410069c4db8>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[target][df[target] == i] = target_dict[i]\n"
     ]
    }
   ],
   "source": [
    "data_path = path.Path(\".\\\\data\")\n",
    "df = pd.read_csv(data_path/\"train.csv\")\n",
    "    \n",
    "dataset = SynteticSet(df, [i for i in range(50)])\n",
    "dataset_len = len(dataset)\n",
    "\n",
    "trainset, evalset = data.random_split(dataset, \n",
    "                                      [int(dataset_len*0.7), int(dataset_len*0.3)])\n",
    "\n",
    "trainloader = data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "evalloader = data.DataLoader(evalset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df.copy()\n",
    "dfc.pop(\"id\")\n",
    "dfc.pop(\"target\")\n",
    "embeddings_dim = list()\n",
    "for i in dfc:\n",
    "    embeddings_dim.append(max(dfc[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(dim+1, 4) for dim in embeddings_dim\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        r = torch.empty(x.shape[1], x.shape[0], 4)\n",
    "        x = x.transpose(0, 1)\n",
    "        for i,data in enumerate(x):\n",
    "            r[i] = self.embeddings[i](data)\n",
    "            \n",
    "        r = r.transpose(1, 0)\n",
    "        return r.mean(dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NN()\n",
    "lossF = nn.CrossEntropyLoss()\n",
    "\n",
    "opt = Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step():\n",
    "    loss_list = list()\n",
    "    for x,y in trainloader:\n",
    "\n",
    "        opt.zero_grad()\n",
    "        result = net(x)\n",
    "        loss = lossF(result, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "    print(np.array(loss_list).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0741822915713573\n",
      "1.0741029693396043\n",
      "1.0740058851416412\n",
      "1.073968080432585\n",
      "1.0739202129993404\n",
      "1.0738145049790795\n",
      "1.0738030203517657\n",
      "1.0737338227371411\n",
      "1.0736662816303957\n",
      "1.0736604036535162\n",
      "1.0735535096424806\n",
      "1.0734896565050267\n",
      "1.0734465579881964\n",
      "1.0734397713401418\n",
      "1.0733179260433483\n",
      "1.07327995287217\n",
      "1.0732253124116762\n",
      "1.0731958741461773\n",
      "1.0731229466101806\n",
      "1.0730808081966867\n",
      "1.0730310597846888\n",
      "1.0729580921490407\n",
      "1.0729235294096213\n",
      "1.0728542244630497\n",
      "1.0728366233313105\n",
      "1.0727569770333536\n",
      "1.072703926829141\n",
      "1.0726545767984617\n",
      "1.0726231173143963\n",
      "1.0725727801567022\n",
      "1.0725384982238086\n",
      "1.072456162416085\n",
      "1.072420281618561\n",
      "1.0723574442662966\n",
      "1.0723347340249056\n",
      "1.0722703008590713\n",
      "1.0721899148968936\n",
      "1.0721395734895083\n",
      "1.072119063716484\n",
      "1.0720571808013009\n",
      "1.072022500269156\n",
      "1.0720049444674573\n",
      "1.0719347573285565\n",
      "1.0719072159509118\n",
      "1.0718450827398074\n",
      "1.071774481310487\n",
      "1.0717381290151606\n",
      "1.0717407991289003\n",
      "1.071656330847871\n",
      "1.0716130444728915\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0963621139526367  Accuracy: 0.5786333084106445\n"
     ]
    }
   ],
   "source": [
    "x, y = evalset[:]\n",
    "result = net(x)\n",
    "accuracy = (result.argmax(dim=1) == y).float().mean()\n",
    "loss = lossF(result, y)\n",
    "\n",
    "print(f\"Loss: {loss}  Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
