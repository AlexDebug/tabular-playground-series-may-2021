{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import path\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynteticSet(data.Dataset):\n",
    "    def __init__(self, df, features, target=\"target\"):\n",
    "        target_dict = {\"Class_1\": 0, \"Class_2\": 1, \"Class_3\": 2, \"Class_4\": 3}\n",
    "        \n",
    "        for i in target_dict:\n",
    "            df[target][df[target] == i] = target_dict[i]\n",
    "           \n",
    "        prefix = \"feature_{}\"\n",
    "        \n",
    "        for i,feature in enumerate(features):\n",
    "            features[i] = prefix.format(str(feature))\n",
    "        \n",
    "            \n",
    "        self.X = torch.tensor(df[features].to_numpy()).float()\n",
    "        self.Y = torch.tensor(df[target].to_numpy(dtype=np.int64))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i].abs().long(), self.Y[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-4410069c4db8>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[target][df[target] == i] = target_dict[i]\n"
     ]
    }
   ],
   "source": [
    "data_path = path.Path(\".\\\\data\")\n",
    "df = pd.read_csv(data_path/\"train.csv\")\n",
    "    \n",
    "dataset = SynteticSet(df, [i for i in range(50)])\n",
    "dataset_len = len(dataset)\n",
    "\n",
    "trainset, evalset = data.random_split(dataset, \n",
    "                                      [int(dataset_len*0.7), int(dataset_len*0.3)])\n",
    "\n",
    "trainloader = data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "evalloader = data.DataLoader(evalset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df.copy()\n",
    "dfc.pop(\"id\")\n",
    "dfc.pop(\"target\")\n",
    "embeddings_dim = list()\n",
    "for i in dfc:\n",
    "    embeddings_dim.append(max(dfc[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",

    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(dim+1, 4) for dim in embeddings_dim\n",
    "        ])\n",
    "        \n",
=======
    "        self.linear = nn.Sequential(\n",
    "                nn.Linear(200,4),\n",
    "                nn.Softmax(dim=1)\n",
    "            )\n",

    "    def forward(self, x):\n",
    "        r = torch.empty(x.shape[1], x.shape[0], 4)\n",
    "        x = x.transpose(0, 1)\n",
    "        for i,data in enumerate(x):\n",
    "            r[i] = self.embeddings[i](data)\n",
    "            \n",
    "        r = r.transpose(1, 0)\n",
    "        return self.linear(r) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NN()\n",
    "lossF = nn.CrossEntropyLoss()\n",
    "\n",
    "opt = Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,

   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step():\n",
    "    loss_list = list()\n",
    "    for x,y in trainloader:\n",
    "\n",
    "        opt.zero_grad()\n",
    "        result = net(x)\n",
    "        loss = lossF(result, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "    print(np.array(loss_list).mean())"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0963621139526367  Accuracy: 0.5786333084106445\n"
     ]
    }
   ],
   "source": [
    "x, y = evalset[:]\n",
    "result = net(x)\n",
    "accuracy = (result.argmax(dim=1) == y).float().mean()\n",
    "loss = lossF(result, y)\n",
    "\n",
    "print(f\"Loss: {loss}  Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
